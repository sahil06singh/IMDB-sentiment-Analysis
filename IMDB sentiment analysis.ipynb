{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescription-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "moral-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expensive-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rational-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment = lb.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-harvest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil Singh\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "standing-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for removing special characters \n",
    "def remove_special_characters(text):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "super-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('English'))\n",
    "ps = PorterStemmer()\n",
    "def remove_stopwords(text):\n",
    "    text = [ps.stem(x) for x in text if x not in stop_words]\n",
    "    return text\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "close-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_words = 10000\n",
    "tokenizer = Tokenizer(num_words = num_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "level-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "trying-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wanted-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(token) for token in tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "double-graham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "activated-desert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "combined-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tokens = pad_sequences(tokens ,maxlen=max_tokens , padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "placed-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train, Y_test = train_test_split(updated_tokens , df.sentiment.values , train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "prerequisite-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=num_of_words,\n",
    "                    output_dim=128,\n",
    "                    input_length=max_tokens),\n",
    "    keras.layers.LSTM(128,dropout=0.2,return_sequences =True),\n",
    "    keras.layers.LSTM(64,dropout=0.2,return_sequences =True),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(1,activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "arbitrary-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "general-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 274, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 274, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 274, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,473,441\n",
      "Trainable params: 1,473,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "advisory-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('bestmodelIMDB.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "confident-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "594/594 [==============================] - 365s 614ms/step - loss: 0.3567 - accuracy: 0.8447 - val_loss: 0.2719 - val_accuracy: 0.8915\n",
      "Epoch 2/16\n",
      "594/594 [==============================] - 4501s 8s/step - loss: 0.2266 - accuracy: 0.9121 - val_loss: 0.2793 - val_accuracy: 0.8875\n",
      "Epoch 3/16\n",
      "594/594 [==============================] - 405s 683ms/step - loss: 0.1821 - accuracy: 0.9313 - val_loss: 0.3581 - val_accuracy: 0.8775\n",
      "Epoch 4/16\n",
      "594/594 [==============================] - 417s 702ms/step - loss: 0.1377 - accuracy: 0.9498 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 5/16\n",
      "594/594 [==============================] - 433s 730ms/step - loss: 0.1144 - accuracy: 0.9598 - val_loss: 0.3888 - val_accuracy: 0.8790\n",
      "Epoch 6/16\n",
      "594/594 [==============================] - 442s 744ms/step - loss: 0.0797 - accuracy: 0.9728 - val_loss: 0.4269 - val_accuracy: 0.8670\n",
      "Epoch 7/16\n",
      "594/594 [==============================] - 435s 732ms/step - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.4601 - val_accuracy: 0.8685\n",
      "Epoch 8/16\n",
      "594/594 [==============================] - 433s 728ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.4721 - val_accuracy: 0.8725\n",
      "Epoch 9/16\n",
      "594/594 [==============================] - 438s 737ms/step - loss: 0.0522 - accuracy: 0.9830 - val_loss: 0.4248 - val_accuracy: 0.8720\n",
      "Epoch 10/16\n",
      "594/594 [==============================] - 433s 730ms/step - loss: 0.0589 - accuracy: 0.9794 - val_loss: 0.5207 - val_accuracy: 0.8625\n",
      "Epoch 11/16\n",
      "594/594 [==============================] - 438s 737ms/step - loss: 0.0331 - accuracy: 0.9901 - val_loss: 0.6060 - val_accuracy: 0.8685\n",
      "Epoch 12/16\n",
      "594/594 [==============================] - 449s 755ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 0.5802 - val_accuracy: 0.8650\n",
      "Epoch 13/16\n",
      "594/594 [==============================] - 1037s 2s/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 0.6033 - val_accuracy: 0.8690\n",
      "Epoch 14/16\n",
      "594/594 [==============================] - 430s 723ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.5972 - val_accuracy: 0.8640\n",
      "Epoch 15/16\n",
      "594/594 [==============================] - 480s 808ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.6554 - val_accuracy: 0.8645\n",
      "Epoch 16/16\n",
      "594/594 [==============================] - 544s 916ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.5846 - val_accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x217a7a20220>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit(X_train, Y_train, epochs = 16, batch_size=batch_size,validation_split=0.05,verbose = True,callbacks =[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "related-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "logical-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 31s 99ms/step - loss: 0.6326 - accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6325933337211609, 0.859000027179718]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-clark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
